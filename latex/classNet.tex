\hypertarget{classNet}{}\section{Net Class Reference}
\label{classNet}\index{Net@{Net}}


The abstract network type upon which all others are based. It\textquotesingle{}s not pure virtual, in that it encapsulates some high level operations (such as the top-\/level training algorithm).  




{\ttfamily \#include $<$net.\+hpp$>$}



Inheritance diagram for Net\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=290pt]{classNet__inherit__graph}
\end{center}
\end{figure}
\subsection*{Classes}
\begin{DoxyCompactItemize}
\item 
struct \hyperlink{structNet_1_1SGDParams}{S\+G\+D\+Params}
\begin{DoxyCompactList}\small\item\em Training parameters for \hyperlink{classNet_a4e527a7773eed5fb071b78ef3a636c95}{train\+S\+G\+D()}. This structure holds the parameters for the \hyperlink{classNet_a4e527a7773eed5fb071b78ef3a636c95}{train\+S\+G\+D()} method, and serves as a better way of passing them than a long parameter list. All values have defaults set up by the constructor, which are given as constants. You can set parameters by hand, but there are fluent (chainable) setters for many members. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
virtual \hyperlink{classNet_a882ce3a3037e5fe06f1a11f87cb0629d}{$\sim$\+Net} ()
\begin{DoxyCompactList}\small\item\em virtual destructor which does nothing \end{DoxyCompactList}\item 
void \hyperlink{classNet_a2ef424e05bfeff073bbca57a5735c121}{set\+Seed} (long seed)
\begin{DoxyCompactList}\small\item\em Set this network\textquotesingle{}s random number generator, which is used for weight initialisation done at the start of training. \end{DoxyCompactList}\item 
virtual int \hyperlink{classNet_a01aa05702b4cc818b9ae860675a6b219}{get\+Layer\+Size} (int n) const =0
\begin{DoxyCompactList}\small\item\em Get the number of nodes in a given layer. \end{DoxyCompactList}\item 
virtual int \hyperlink{classNet_a84682330293fe317a8b483eed2987939}{get\+Layer\+Count} () const =0
\begin{DoxyCompactList}\small\item\em Get the number of layers. \end{DoxyCompactList}\item 
int \hyperlink{classNet_a53df5c1c5703b73ee5a7ccb7537b66a9}{get\+Input\+Count} () const 
\begin{DoxyCompactList}\small\item\em get the number of inputs \end{DoxyCompactList}\item 
int \hyperlink{classNet_a5f96e2ae07bec62b8c97ab192528f3c3}{get\+Output\+Count} () const 
\begin{DoxyCompactList}\small\item\em get the number of outputs \end{DoxyCompactList}\item 
virtual void \hyperlink{classNet_a3c41ce6877aa3b04e5c19943bc78d007}{set\+Inputs} (double $\ast$d)=0
\begin{DoxyCompactList}\small\item\em Set the inputs to the network before running or training. \end{DoxyCompactList}\item 
virtual double $\ast$ \hyperlink{classNet_a38d901e18a4a269ca7ed3766cc4b4079}{get\+Outputs} () const =0
\begin{DoxyCompactList}\small\item\em Get the outputs after running. \end{DoxyCompactList}\item 
double $\ast$ \hyperlink{classNet_a3f711482dd39b9653f4449304b853a79}{run} (double $\ast$in)
\begin{DoxyCompactList}\small\item\em Run the network on some data. \end{DoxyCompactList}\item 
virtual void \hyperlink{classNet_a5a01870e21e29845252d6bec88b0c497}{setH} (double h)=0
\begin{DoxyCompactList}\small\item\em Set the modulator level for subsequent runs and training of this network. \end{DoxyCompactList}\item 
virtual double \hyperlink{classNet_afc3db6d4a7b1307b359f98da0b9b3bf2}{getH} () const =0
\begin{DoxyCompactList}\small\item\em get the modulator level \end{DoxyCompactList}\item 
double \hyperlink{classNet_a5b4d9d5fcf5b31d2ae163cbe3f5b151f}{test} (\hyperlink{classExampleSet}{Example\+Set} \&examples, int start=0, int num=-\/1)
\begin{DoxyCompactList}\small\item\em Test a network. Runs the network over a set of examples and returns the mean M\+SE for all outputs \[ \frac{1}{N\cdot N_{outs}}\sum^N_{e \in Examples} \sum_{i=0}^{N_{outs}} (e_o(i) - e_y(i))^2 \] where $N$ is the number of examples, $N_{outs}$ is the number of outputs, $e_o(i)$ is network\textquotesingle{}s output for example $e$, and $e_y(i)$ is the desired output for the same example. \end{DoxyCompactList}\item 
double \hyperlink{classNet_a4e527a7773eed5fb071b78ef3a636c95}{train\+S\+GD} (\hyperlink{classExampleSet}{Example\+Set} \&examples, \hyperlink{structNet_1_1SGDParams}{S\+G\+D\+Params} \&params)
\begin{DoxyCompactList}\small\item\em Train using stochastic gradient descent. Note that cross-\/validation parameters are slightly different from those given in the thesis. Here we give the number of slices and number of examples per slice; in the thesis we give the total number of examples to be held out and the number of slices. \end{DoxyCompactList}\item 
virtual int \hyperlink{classNet_a18dfc4bbf338d5167e787edefef8cd43}{get\+Data\+Size} () const =0
\begin{DoxyCompactList}\small\item\em Get the length of the serialised data block for this network. \end{DoxyCompactList}\item 
virtual void \hyperlink{classNet_ad1178bdda5ebb1dc1bb57dc3da727fce}{save} (double $\ast$buf) const =0
\begin{DoxyCompactList}\small\item\em Serialize the data (not including any network type magic number or layer/node counts) to the given memory (which must be of sufficient size). \end{DoxyCompactList}\item 
virtual void \hyperlink{classNet_a6fc4cac6c8e32acc1d3567defcce9b8c}{load} (double $\ast$buf)=0
\begin{DoxyCompactList}\small\item\em Given that the pointer points to a data block of the correct size for the current network, copy the parameters from that data block into the current network overwriting the current parameters. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{netType_8hpp_a1526df0fc932ccf720aa26267f923213}{Net\+Type} \hyperlink{classNet_a6b6b0fb9e01f10084ce304df6d8c841d}{type}
\begin{DoxyCompactList}\small\item\em type of the network, used for load/save \end{DoxyCompactList}\item 
drand48\+\_\+data \hyperlink{classNet_a364288d09aeae0b47c5adbfb470a6c1c}{rd}
\begin{DoxyCompactList}\small\item\em P\+R\+NG data (thread safe) \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
virtual void \hyperlink{classNet_ad02198e219d3ba060c88d764ce54b905}{update} ()=0
\begin{DoxyCompactList}\small\item\em Run a single update of the network. \end{DoxyCompactList}\item 
\hyperlink{classNet_a4bb31bf5599d954de2062747166b7dff}{Net} (\hyperlink{netType_8hpp_a1526df0fc932ccf720aa26267f923213}{Net\+Type} tp)
\begin{DoxyCompactList}\small\item\em Constructor -\/ protected because others inherit it and it\textquotesingle{}s not used directly. \end{DoxyCompactList}\item 
double \hyperlink{classNet_aede931306b87045c0e6f14ee947a8ef7}{drand} (double mn, double mx)
\begin{DoxyCompactList}\small\item\em get a random number using this net\textquotesingle{}s P\+R\+NG data \end{DoxyCompactList}\item 
virtual void \hyperlink{classNet_a5bbf19d2255b0c8418c9bd54930290cf}{init\+Weights} (double initr)=0
\begin{DoxyCompactList}\small\item\em initialise weights to random values \end{DoxyCompactList}\item 
virtual double \hyperlink{classNet_a6ac1fa9f916aa77906581af9140b8175}{train\+Batch} (\hyperlink{classExampleSet}{Example\+Set} \&ex, int start, int num, double eta)=0
\begin{DoxyCompactList}\small\item\em Train a network for batch (or mini-\/batch) (or single example). \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Friends}
\begin{DoxyCompactItemize}
\item 
class \hyperlink{classNet_a9ffff8d20e4d424b4358f43e204c7d1b}{Output\+Blending\+Net}
\item 
class \hyperlink{classNet_a8e75331604ab50e15c580aeb31b3804f}{H\+Input\+Net}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
The abstract network type upon which all others are based. It\textquotesingle{}s not pure virtual, in that it encapsulates some high level operations (such as the top-\/level training algorithm). 

Definition at line 39 of file net.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\index{Net@{Net}!````~Net@{$\sim$\+Net}}
\index{````~Net@{$\sim$\+Net}!Net@{Net}}
\subsubsection[{\texorpdfstring{$\sim$\+Net()}{~Net()}}]{\setlength{\rightskip}{0pt plus 5cm}virtual Net\+::$\sim$\+Net (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}\hypertarget{classNet_a882ce3a3037e5fe06f1a11f87cb0629d}{}\label{classNet_a882ce3a3037e5fe06f1a11f87cb0629d}


virtual destructor which does nothing 



Definition at line 47 of file net.\+hpp.

\index{Net@{Net}!Net@{Net}}
\index{Net@{Net}!Net@{Net}}
\subsubsection[{\texorpdfstring{Net(\+Net\+Type tp)}{Net(NetType tp)}}]{\setlength{\rightskip}{0pt plus 5cm}Net\+::\+Net (
\begin{DoxyParamCaption}
\item[{{\bf Net\+Type}}]{tp}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [protected]}}\hypertarget{classNet_a4bb31bf5599d954de2062747166b7dff}{}\label{classNet_a4bb31bf5599d954de2062747166b7dff}


Constructor -\/ protected because others inherit it and it\textquotesingle{}s not used directly. 


\begin{DoxyParams}{Parameters}
{\em tp} & network type enumeration \\
\hline
\end{DoxyParams}


Definition at line 580 of file net.\+hpp.



\subsection{Member Function Documentation}
\index{Net@{Net}!drand@{drand}}
\index{drand@{drand}!Net@{Net}}
\subsubsection[{\texorpdfstring{drand(double mn, double mx)}{drand(double mn, double mx)}}]{\setlength{\rightskip}{0pt plus 5cm}double Net\+::drand (
\begin{DoxyParamCaption}
\item[{double}]{mn, }
\item[{double}]{mx}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [protected]}}\hypertarget{classNet_aede931306b87045c0e6f14ee947a8ef7}{}\label{classNet_aede931306b87045c0e6f14ee947a8ef7}


get a random number using this net\textquotesingle{}s P\+R\+NG data 


\begin{DoxyParams}{Parameters}
{\em mn} & minimum value (inclusive) \\
\hline
{\em mx} & maximum value (inclusive) \\
\hline
\end{DoxyParams}


Definition at line 591 of file net.\+hpp.

\index{Net@{Net}!get\+Data\+Size@{get\+Data\+Size}}
\index{get\+Data\+Size@{get\+Data\+Size}!Net@{Net}}
\subsubsection[{\texorpdfstring{get\+Data\+Size() const =0}{getDataSize() const =0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual int Net\+::get\+Data\+Size (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_a18dfc4bbf338d5167e787edefef8cd43}{}\label{classNet_a18dfc4bbf338d5167e787edefef8cd43}


Get the length of the serialised data block for this network. 

\begin{DoxyReturn}{Returns}
the size in doubles 
\end{DoxyReturn}


Implemented in \hyperlink{classBPNet_ab0071a9b17ba5d42959ce600d29a255c}{B\+P\+Net}, and \hyperlink{classOutputBlendingNet_a1196e5ab4cc8326308395d91f7128454}{Output\+Blending\+Net}.

\index{Net@{Net}!getH@{getH}}
\index{getH@{getH}!Net@{Net}}
\subsubsection[{\texorpdfstring{get\+H() const =0}{getH() const =0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual double Net\+::getH (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_afc3db6d4a7b1307b359f98da0b9b3bf2}{}\label{classNet_afc3db6d4a7b1307b359f98da0b9b3bf2}


get the modulator level 



Implemented in \hyperlink{classBPNet_aef1082e622022f25bee51013fab29aa0}{B\+P\+Net}, \hyperlink{classHInputNet_aa79dc2d56582978e28661e0f6163d163}{H\+Input\+Net}, \hyperlink{classOutputBlendingNet_a1d8ff29c1f29c431df31f9e22c89d529}{Output\+Blending\+Net}, and \hyperlink{classUESNet_a421efc8741f28e65931e2b8affa7c149}{U\+E\+S\+Net}.

\index{Net@{Net}!get\+Input\+Count@{get\+Input\+Count}}
\index{get\+Input\+Count@{get\+Input\+Count}!Net@{Net}}
\subsubsection[{\texorpdfstring{get\+Input\+Count() const }{getInputCount() const }}]{\setlength{\rightskip}{0pt plus 5cm}int Net\+::get\+Input\+Count (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\hypertarget{classNet_a53df5c1c5703b73ee5a7ccb7537b66a9}{}\label{classNet_a53df5c1c5703b73ee5a7ccb7537b66a9}


get the number of inputs 



Definition at line 75 of file net.\+hpp.

\index{Net@{Net}!get\+Layer\+Count@{get\+Layer\+Count}}
\index{get\+Layer\+Count@{get\+Layer\+Count}!Net@{Net}}
\subsubsection[{\texorpdfstring{get\+Layer\+Count() const =0}{getLayerCount() const =0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual int Net\+::get\+Layer\+Count (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_a84682330293fe317a8b483eed2987939}{}\label{classNet_a84682330293fe317a8b483eed2987939}


Get the number of layers. 



Implemented in \hyperlink{classBPNet_af52311c47d488b0121ea59574e2b9c05}{B\+P\+Net}, and \hyperlink{classOutputBlendingNet_ade2a917996b0325fd4b23d1584645d1a}{Output\+Blending\+Net}.

\index{Net@{Net}!get\+Layer\+Size@{get\+Layer\+Size}}
\index{get\+Layer\+Size@{get\+Layer\+Size}!Net@{Net}}
\subsubsection[{\texorpdfstring{get\+Layer\+Size(int n) const =0}{getLayerSize(int n) const =0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual int Net\+::get\+Layer\+Size (
\begin{DoxyParamCaption}
\item[{int}]{n}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_a01aa05702b4cc818b9ae860675a6b219}{}\label{classNet_a01aa05702b4cc818b9ae860675a6b219}


Get the number of nodes in a given layer. 


\begin{DoxyParams}{Parameters}
{\em n} & layer number \\
\hline
\end{DoxyParams}


Implemented in \hyperlink{classBPNet_afbf10480c672d8a6e3cbf4071f447cc8}{B\+P\+Net}, \hyperlink{classHInputNet_a70a98f13c5a0ee60aaa28438dfc734f8}{H\+Input\+Net}, and \hyperlink{classOutputBlendingNet_ad31f525182b2949d406a203189b65ae8}{Output\+Blending\+Net}.

\index{Net@{Net}!get\+Output\+Count@{get\+Output\+Count}}
\index{get\+Output\+Count@{get\+Output\+Count}!Net@{Net}}
\subsubsection[{\texorpdfstring{get\+Output\+Count() const }{getOutputCount() const }}]{\setlength{\rightskip}{0pt plus 5cm}int Net\+::get\+Output\+Count (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}\hypertarget{classNet_a5f96e2ae07bec62b8c97ab192528f3c3}{}\label{classNet_a5f96e2ae07bec62b8c97ab192528f3c3}


get the number of outputs 



Definition at line 82 of file net.\+hpp.

\index{Net@{Net}!get\+Outputs@{get\+Outputs}}
\index{get\+Outputs@{get\+Outputs}!Net@{Net}}
\subsubsection[{\texorpdfstring{get\+Outputs() const =0}{getOutputs() const =0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual double$\ast$ Net\+::get\+Outputs (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_a38d901e18a4a269ca7ed3766cc4b4079}{}\label{classNet_a38d901e18a4a269ca7ed3766cc4b4079}


Get the outputs after running. 

\begin{DoxyReturn}{Returns}
pointer to the output layer outputs 
\end{DoxyReturn}


Implemented in \hyperlink{classBPNet_adf9256df2239cdef0cb7ad3b45d0e06e}{B\+P\+Net}, and \hyperlink{classOutputBlendingNet_a6ea58b1ae8d0f5e6ff3b0f616de63eb5}{Output\+Blending\+Net}.

\index{Net@{Net}!init\+Weights@{init\+Weights}}
\index{init\+Weights@{init\+Weights}!Net@{Net}}
\subsubsection[{\texorpdfstring{init\+Weights(double initr)=0}{initWeights(double initr)=0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual void Net\+::init\+Weights (
\begin{DoxyParamCaption}
\item[{double}]{initr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [pure virtual]}}\hypertarget{classNet_a5bbf19d2255b0c8418c9bd54930290cf}{}\label{classNet_a5bbf19d2255b0c8418c9bd54930290cf}


initialise weights to random values 


\begin{DoxyParams}{Parameters}
{\em initr} & range of weights \mbox{[}-\/n,n\mbox{]}, or -\/1 for Bishop\textquotesingle{}s rule. \\
\hline
\end{DoxyParams}


Implemented in \hyperlink{classBPNet_ae1b90b3c92f6be9af29005371da66543}{B\+P\+Net}, and \hyperlink{classOutputBlendingNet_abb65aa0c88e2e29a17b4f91e1c6d7b03}{Output\+Blending\+Net}.

\index{Net@{Net}!load@{load}}
\index{load@{load}!Net@{Net}}
\subsubsection[{\texorpdfstring{load(double $\ast$buf)=0}{load(double *buf)=0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual void Net\+::load (
\begin{DoxyParamCaption}
\item[{double $\ast$}]{buf}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_a6fc4cac6c8e32acc1d3567defcce9b8c}{}\label{classNet_a6fc4cac6c8e32acc1d3567defcce9b8c}


Given that the pointer points to a data block of the correct size for the current network, copy the parameters from that data block into the current network overwriting the current parameters. 


\begin{DoxyParams}{Parameters}
{\em buf} & the buffer to load the data from, must be at least \hyperlink{classNet_a18dfc4bbf338d5167e787edefef8cd43}{get\+Data\+Size()} doubles \\
\hline
\end{DoxyParams}


Implemented in \hyperlink{classBPNet_a11724f2263de9dcbc0f9172b464732c7}{B\+P\+Net}, and \hyperlink{classOutputBlendingNet_a97c9054693c98b2771763b38c5576d47}{Output\+Blending\+Net}.

\index{Net@{Net}!run@{run}}
\index{run@{run}!Net@{Net}}
\subsubsection[{\texorpdfstring{run(double $\ast$in)}{run(double *in)}}]{\setlength{\rightskip}{0pt plus 5cm}double$\ast$ Net\+::run (
\begin{DoxyParamCaption}
\item[{double $\ast$}]{in}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\hypertarget{classNet_a3f711482dd39b9653f4449304b853a79}{}\label{classNet_a3f711482dd39b9653f4449304b853a79}


Run the network on some data. 


\begin{DoxyParams}{Parameters}
{\em in} & pointer to the input double array \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
pointer to the output double array 
\end{DoxyReturn}


Definition at line 107 of file net.\+hpp.

\index{Net@{Net}!save@{save}}
\index{save@{save}!Net@{Net}}
\subsubsection[{\texorpdfstring{save(double $\ast$buf) const =0}{save(double *buf) const =0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual void Net\+::save (
\begin{DoxyParamCaption}
\item[{double $\ast$}]{buf}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_ad1178bdda5ebb1dc1bb57dc3da727fce}{}\label{classNet_ad1178bdda5ebb1dc1bb57dc3da727fce}


Serialize the data (not including any network type magic number or layer/node counts) to the given memory (which must be of sufficient size). 


\begin{DoxyParams}{Parameters}
{\em buf} & the buffer to save the data, must be at least \hyperlink{classNet_a18dfc4bbf338d5167e787edefef8cd43}{get\+Data\+Size()} doubles \\
\hline
\end{DoxyParams}


Implemented in \hyperlink{classBPNet_a7ef14370548350daecedcb275ba88c07}{B\+P\+Net}, and \hyperlink{classOutputBlendingNet_a9520621635c8b05d472be9185a341475}{Output\+Blending\+Net}.

\index{Net@{Net}!setH@{setH}}
\index{setH@{setH}!Net@{Net}}
\subsubsection[{\texorpdfstring{set\+H(double h)=0}{setH(double h)=0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual void Net\+::setH (
\begin{DoxyParamCaption}
\item[{double}]{h}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_a5a01870e21e29845252d6bec88b0c497}{}\label{classNet_a5a01870e21e29845252d6bec88b0c497}


Set the modulator level for subsequent runs and training of this network. 



Implemented in \hyperlink{classBPNet_a98fa374aec169a3e741f2ce96fac7094}{B\+P\+Net}, \hyperlink{classHInputNet_a3ac18a3e39fc58647052518e507ae378}{H\+Input\+Net}, \hyperlink{classOutputBlendingNet_a089d2182d13a9f4dea2093843754dce7}{Output\+Blending\+Net}, and \hyperlink{classUESNet_ad05de4582dd40ae714fce3f9b0d3d2ca}{U\+E\+S\+Net}.

\index{Net@{Net}!set\+Inputs@{set\+Inputs}}
\index{set\+Inputs@{set\+Inputs}!Net@{Net}}
\subsubsection[{\texorpdfstring{set\+Inputs(double $\ast$d)=0}{setInputs(double *d)=0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual void Net\+::set\+Inputs (
\begin{DoxyParamCaption}
\item[{double $\ast$}]{d}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [pure virtual]}}\hypertarget{classNet_a3c41ce6877aa3b04e5c19943bc78d007}{}\label{classNet_a3c41ce6877aa3b04e5c19943bc78d007}


Set the inputs to the network before running or training. 


\begin{DoxyParams}{Parameters}
{\em d} & array of doubles, the size of the input layer \\
\hline
\end{DoxyParams}


Implemented in \hyperlink{classBPNet_ad95c2a033ee8246637a6ce55e685429a}{B\+P\+Net}, \hyperlink{classHInputNet_a2c463ec5781f9e84865747e8bb085065}{H\+Input\+Net}, and \hyperlink{classOutputBlendingNet_a0ecd8c43dfce07092a8e7de0fc734bd4}{Output\+Blending\+Net}.

\index{Net@{Net}!set\+Seed@{set\+Seed}}
\index{set\+Seed@{set\+Seed}!Net@{Net}}
\subsubsection[{\texorpdfstring{set\+Seed(long seed)}{setSeed(long seed)}}]{\setlength{\rightskip}{0pt plus 5cm}void Net\+::set\+Seed (
\begin{DoxyParamCaption}
\item[{long}]{seed}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\hypertarget{classNet_a2ef424e05bfeff073bbca57a5735c121}{}\label{classNet_a2ef424e05bfeff073bbca57a5735c121}


Set this network\textquotesingle{}s random number generator, which is used for weight initialisation done at the start of training. 



Definition at line 57 of file net.\+hpp.

\index{Net@{Net}!test@{test}}
\index{test@{test}!Net@{Net}}
\subsubsection[{\texorpdfstring{test(\+Example\+Set \&examples, int start=0, int num=-\/1)}{test(ExampleSet &examples, int start=0, int num=-1)}}]{\setlength{\rightskip}{0pt plus 5cm}double Net\+::test (
\begin{DoxyParamCaption}
\item[{{\bf Example\+Set} \&}]{examples, }
\item[{int}]{start = {\ttfamily 0}, }
\item[{int}]{num = {\ttfamily -\/1}}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\hypertarget{classNet_a5b4d9d5fcf5b31d2ae163cbe3f5b151f}{}\label{classNet_a5b4d9d5fcf5b31d2ae163cbe3f5b151f}


Test a network. Runs the network over a set of examples and returns the mean M\+SE for all outputs \[ \frac{1}{N\cdot N_{outs}}\sum^N_{e \in Examples} \sum_{i=0}^{N_{outs}} (e_o(i) - e_y(i))^2 \] where $N$ is the number of examples, $N_{outs}$ is the number of outputs, $e_o(i)$ is network\textquotesingle{}s output for example $e$, and $e_y(i)$ is the desired output for the same example. 


\begin{DoxyParams}{Parameters}
{\em examples} & Example set to test (or partially test). \\
\hline
{\em start} & index of example to start test at. \\
\hline
{\em num} & number of examples to test (or -\/1 for all after start point). \\
\hline
\end{DoxyParams}


Definition at line 142 of file net.\+hpp.

\index{Net@{Net}!train\+Batch@{train\+Batch}}
\index{train\+Batch@{train\+Batch}!Net@{Net}}
\subsubsection[{\texorpdfstring{train\+Batch(\+Example\+Set \&ex, int start, int num, double eta)=0}{trainBatch(ExampleSet &ex, int start, int num, double eta)=0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual double Net\+::train\+Batch (
\begin{DoxyParamCaption}
\item[{{\bf Example\+Set} \&}]{ex, }
\item[{int}]{start, }
\item[{int}]{num, }
\item[{double}]{eta}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [pure virtual]}}\hypertarget{classNet_a6ac1fa9f916aa77906581af9140b8175}{}\label{classNet_a6ac1fa9f916aa77906581af9140b8175}


Train a network for batch (or mini-\/batch) (or single example). 

This will
\begin{DoxyItemize}
\item zero the average gradient variables for all weights and biases
\item zero the total error
\item for each example
\begin{DoxyItemize}
\item calculate the error with calc\+Error() which itself calls \hyperlink{classNet_ad02198e219d3ba060c88d764ce54b905}{update()}
\item add to the total mean squared error (see N\+O\+TE below)
\end{DoxyItemize}
\item for each weight and bias
\begin{DoxyItemize}
\item calculate the means across all provided examples
\item apply the mean to the weight or bias
\end{DoxyItemize}
\item return the mean squared error (N\+O\+TE\+: different from original, which returned mean absolute error) for all outputs and examples\+: \[ \frac{1}{N\cdot N_{outs}}\sum^N_{e \in Examples} \sum_{i=0}^{N_{outs}} (e_o(i) - e_y(i))^2 \] where $N$ is the number of examples, $N_{outs}$ is the number of outputs, $e_o(i)$ is network\textquotesingle{}s output for example $e$, and $e_y(i)$ is the desired output for the same example. 
\begin{DoxyParams}{Parameters}
{\em ex} & example set \\
\hline
{\em start} & index of first example to use \\
\hline
{\em num} & number of examples. For a single example, you\textquotesingle{}d just use 1. \\
\hline
{\em eta} & learning rate \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
the sum of mean squared errors in the output layer (see formula in method documentation) 
\end{DoxyReturn}

\end{DoxyItemize}

Implemented in \hyperlink{classBPNet_a3f820464f3338ed7305e9de950cd2103}{B\+P\+Net}, \hyperlink{classOutputBlendingNet_a4c65f752aeedb75c230773965d35df3b}{Output\+Blending\+Net}, and \hyperlink{classUESNet_ac27da7319d8be1507ea80506e69437e5}{U\+E\+S\+Net}.

\index{Net@{Net}!train\+S\+GD@{train\+S\+GD}}
\index{train\+S\+GD@{train\+S\+GD}!Net@{Net}}
\subsubsection[{\texorpdfstring{train\+S\+G\+D(\+Example\+Set \&examples, S\+G\+D\+Params \&params)}{trainSGD(ExampleSet &examples, SGDParams &params)}}]{\setlength{\rightskip}{0pt plus 5cm}double Net\+::train\+S\+GD (
\begin{DoxyParamCaption}
\item[{{\bf Example\+Set} \&}]{examples, }
\item[{{\bf S\+G\+D\+Params} \&}]{params}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}\hypertarget{classNet_a4e527a7773eed5fb071b78ef3a636c95}{}\label{classNet_a4e527a7773eed5fb071b78ef3a636c95}


Train using stochastic gradient descent. Note that cross-\/validation parameters are slightly different from those given in the thesis. Here we give the number of slices and number of examples per slice; in the thesis we give the total number of examples to be held out and the number of slices. 

\begin{DoxyPrecond}{Precondition}
Network has weights initialised to random values 
\end{DoxyPrecond}
\begin{DoxyPostcond}{Postcondition}
The network will be set to the best network found if best\+Net\+Buffer is set, otherwise the final network will be used. 
\end{DoxyPostcond}

\begin{DoxyExceptions}{Exceptions}
{\em std\+::out\+\_\+of\+\_\+range} & Too many CV examples \\
\hline
{\em std\+::logic\+\_\+error} & Trying to select best by CV when there\textquotesingle{}s no CV done\\
\hline
\end{DoxyExceptions}

\begin{DoxyParams}{Parameters}
{\em examples} & training set (including cross-\/validation data) \\
\hline
{\em params} & a filled-\/in \hyperlink{structNet_1_1SGDParams}{S\+G\+D\+Params} structure giving the parameters for the training. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
If store\+Best\+Net is null, the M\+SE of the final network; otherwise the M\+SE of the best network found. This is done across the entire validation set if provided, or the entire training set if not. 
\end{DoxyReturn}


Definition at line 428 of file net.\+hpp.

\index{Net@{Net}!update@{update}}
\index{update@{update}!Net@{Net}}
\subsubsection[{\texorpdfstring{update()=0}{update()=0}}]{\setlength{\rightskip}{0pt plus 5cm}virtual void Net\+::update (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [pure virtual]}}\hypertarget{classNet_ad02198e219d3ba060c88d764ce54b905}{}\label{classNet_ad02198e219d3ba060c88d764ce54b905}


Run a single update of the network. 

\begin{DoxyPrecond}{Precondition}
input layer must be filled with values 
\end{DoxyPrecond}
\begin{DoxyPostcond}{Postcondition}
output layer contains result 
\end{DoxyPostcond}


Implemented in \hyperlink{classBPNet_af60f5bfa6cb7dffd75a9a127b811a208}{B\+P\+Net}, \hyperlink{classOutputBlendingNet_a879f1eedcfad5238d9bdbc78ef5f8250}{Output\+Blending\+Net}, and \hyperlink{classUESNet_a1d05fcd3ce9f188db8841a9d6fc6c56c}{U\+E\+S\+Net}.



\subsection{Friends And Related Function Documentation}
\index{Net@{Net}!H\+Input\+Net@{H\+Input\+Net}}
\index{H\+Input\+Net@{H\+Input\+Net}!Net@{Net}}
\subsubsection[{\texorpdfstring{H\+Input\+Net}{HInputNet}}]{\setlength{\rightskip}{0pt plus 5cm}friend class {\bf H\+Input\+Net}\hspace{0.3cm}{\ttfamily [friend]}}\hypertarget{classNet_a8e75331604ab50e15c580aeb31b3804f}{}\label{classNet_a8e75331604ab50e15c580aeb31b3804f}


Definition at line 41 of file net.\+hpp.

\index{Net@{Net}!Output\+Blending\+Net@{Output\+Blending\+Net}}
\index{Output\+Blending\+Net@{Output\+Blending\+Net}!Net@{Net}}
\subsubsection[{\texorpdfstring{Output\+Blending\+Net}{OutputBlendingNet}}]{\setlength{\rightskip}{0pt plus 5cm}friend class {\bf Output\+Blending\+Net}\hspace{0.3cm}{\ttfamily [friend]}}\hypertarget{classNet_a9ffff8d20e4d424b4358f43e204c7d1b}{}\label{classNet_a9ffff8d20e4d424b4358f43e204c7d1b}


Definition at line 40 of file net.\+hpp.



\subsection{Member Data Documentation}
\index{Net@{Net}!rd@{rd}}
\index{rd@{rd}!Net@{Net}}
\subsubsection[{\texorpdfstring{rd}{rd}}]{\setlength{\rightskip}{0pt plus 5cm}drand48\+\_\+data Net\+::rd}\hypertarget{classNet_a364288d09aeae0b47c5adbfb470a6c1c}{}\label{classNet_a364288d09aeae0b47c5adbfb470a6c1c}


P\+R\+NG data (thread safe) 



Definition at line 50 of file net.\+hpp.

\index{Net@{Net}!type@{type}}
\index{type@{type}!Net@{Net}}
\subsubsection[{\texorpdfstring{type}{type}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf Net\+Type} Net\+::type}\hypertarget{classNet_a6b6b0fb9e01f10084ce304df6d8c841d}{}\label{classNet_a6b6b0fb9e01f10084ce304df6d8c841d}


type of the network, used for load/save 



Definition at line 49 of file net.\+hpp.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/travis/build/jimfinnis/uesmanncpp/\hyperlink{net_8hpp}{net.\+hpp}\end{DoxyCompactItemize}
