\section{Class List}
Here are the classes, structs, unions and interfaces with brief descriptions\+:\begin{DoxyCompactList}
\item\contentsline{section}{\hyperlink{classBooleanExampleSet}{Boolean\+Example\+Set} \\*Boolean example set\+: 16 examples, 2 inputs, 1 output, 2 mod levels. There are 4 examples for each function and they\textquotesingle{}re repeated twice, so we can do \char`\"{}cross-\/validation\char`\"{} on the identical second half }{\pageref{classBooleanExampleSet}}{}
\item\contentsline{section}{\hyperlink{classBPNet}{B\+P\+Net} \\*The \char`\"{}basic\char`\"{} back-\/propagation network using a logistic sigmoid, as described by Rumelhart, Hinton and Williams (and many others). This class is used by output blending and h-\/as-\/input networks }{\pageref{classBPNet}}{}
\item\contentsline{section}{\hyperlink{classExampleSet}{Example\+Set} \\*A set of example data. Each datum consists of hormone (i.\+e. modulator value), inputs and outputs. The data is stored as a single double array, with each example made up of inputs, followed by outputs, followed by modulator value (h) }{\pageref{classExampleSet}}{}
\item\contentsline{section}{\hyperlink{classHInputNet}{H\+Input\+Net} \\*A modulatory network architecture which uses a plain backprop network with an extra input to carry the modulator }{\pageref{classHInputNet}}{}
\item\contentsline{section}{\hyperlink{classMNIST}{M\+N\+I\+ST} \\*This class encapsulates and loads data in the standard \hyperlink{classMNIST}{M\+N\+I\+ST} format. The data resides in two files, an image file and a label file }{\pageref{classMNIST}}{}
\item\contentsline{section}{\hyperlink{classNet}{Net} \\*The abstract network type upon which all others are based. It\textquotesingle{}s not pure virtual, in that it encapsulates some high level operations (such as the top-\/level training algorithm) }{\pageref{classNet}}{}
\item\contentsline{section}{\hyperlink{classNetFactory}{Net\+Factory} \\*This class -\/ really a namespace -\/ contains functions which create, load or save networks of all types }{\pageref{classNetFactory}}{}
\item\contentsline{section}{\hyperlink{classOutputBlendingNet}{Output\+Blending\+Net} \\*A modulatory network architecture which uses two plain backprop networks, each of which is trained separately. When the network is run, each subnetwork is run and the output generated by interpolating between the subnet outputs }{\pageref{classOutputBlendingNet}}{}
\item\contentsline{section}{\hyperlink{structNet_1_1SGDParams}{Net\+::\+S\+G\+D\+Params} \\*Training parameters for \hyperlink{classNet_a4e527a7773eed5fb071b78ef3a636c95}{train\+S\+G\+D()}. This structure holds the parameters for the \hyperlink{classNet_a4e527a7773eed5fb071b78ef3a636c95}{train\+S\+G\+D()} method, and serves as a better way of passing them than a long parameter list. All values have defaults set up by the constructor, which are given as constants. You can set parameters by hand, but there are fluent (chainable) setters for many members }{\pageref{structNet_1_1SGDParams}}{}
\item\contentsline{section}{\hyperlink{classTestExampleSet}{Test\+Example\+Set} \\*Utility test class. Constructs a standard set\+: 10 examples, 5 ins, 2 outs\+: }{\pageref{classTestExampleSet}}{}
\item\contentsline{section}{\hyperlink{classUESNet}{U\+E\+S\+Net} \\*The U\+E\+S\+M\+A\+NN network, which it itself based on the \hyperlink{classBPNet}{B\+P\+Net} code as it has the same architecture as the plain M\+LP }{\pageref{classUESNet}}{}
\end{DoxyCompactList}
