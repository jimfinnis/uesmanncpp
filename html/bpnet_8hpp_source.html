<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>UESMANN CPP: /home/travis/build/jimfinnis/uesmanncpp/bpnet.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">UESMANN CPP
   &#160;<span id="projectnumber">1.0</span>
   </div>
   <div id="projectbrief">Reference implementation of UESMANN</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">/home/travis/build/jimfinnis/uesmanncpp/bpnet.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="bpnet_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="preprocessor">#ifndef __BPNET_HPP</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#define __BPNET_HPP</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="net_8hpp.html">net.hpp</a>&quot;</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div><div class="line"><a name="l00018"></a><span class="lineno"><a class="line" href="classBPNet.html">   18</a></span>&#160;<span class="keyword">class </span><a class="code" href="classBPNet.html">BPNet</a> : <span class="keyword">public</span> <a class="code" href="classNet.html">Net</a> {</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00024"></a><span class="lineno"><a class="line" href="classBPNet.html#ad9b8ec22ef6319ebda7b3ac996b76f3e">   24</a></span>&#160;    <a class="code" href="classBPNet.html#ad9b8ec22ef6319ebda7b3ac996b76f3e">BPNet</a>() : <a class="code" href="classNet.html">Net</a> (<a class="code" href="netType_8hpp.html#a1526df0fc932ccf720aa26267f923213">NetType</a>::<a class="code" href="netType_8hpp.html#a1526df0fc932ccf720aa26267f923213af62eb0bf5e5c72e80983fbbac1cb70e5">PLAIN</a>) {</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;    }</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;    </div><div class="line"><a name="l00032"></a><span class="lineno"><a class="line" href="classBPNet.html#ada480f784f72fb5de132ce368adde531">   32</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#ada480f784f72fb5de132ce368adde531">init</a>(<span class="keywordtype">int</span> nlayers,<span class="keyword">const</span> <span class="keywordtype">int</span> *layerCounts){</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;        <a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a> = nlayers;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;        <a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>* [<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>];</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;        <a class="code" href="classBPNet.html#a6b60b49ea0c157bbe4d785f74fa3f208">errors</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>* [<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>];</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;        <a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a> = <span class="keyword">new</span> <span class="keywordtype">int</span> [<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>];</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;        <a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>=0;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;i++){</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;            <span class="keywordtype">int</span> n = layerCounts[i];</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;            <a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a>[i] = <span class="keyword">new</span> <span class="keywordtype">double</span>[n];</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;            <a class="code" href="classBPNet.html#a6b60b49ea0c157bbe4d785f74fa3f208">errors</a>[i] = <span class="keyword">new</span> <span class="keywordtype">double</span>[n];</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k=0;k&lt;n;k++)</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;                <a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a>[i][k]=0;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;            <a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a>[i]=n;</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;            <span class="keywordflow">if</span>(n&gt;<a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>)</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;                <a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>=n;</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        }</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;        </div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;        <a class="code" href="classBPNet.html#aca57e8583a315a709a27e4dffeefd493">weights</a> = <span class="keyword">new</span> <span class="keywordtype">double</span> * [<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>];</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;        <a class="code" href="classBPNet.html#a72567d85f25041df70225b5e98ae3b90">gradAvgsWeights</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>* [<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>];</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;        <a class="code" href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">biases</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>* [<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>];</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;        <a class="code" href="classBPNet.html#a90e9fb8bde12a2520186d8084628109b">gradAvgsBiases</a> = <span class="keyword">new</span> <span class="keywordtype">double</span>* [<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>];</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;i++){</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;            <span class="keywordtype">int</span> n = layerCounts[i];</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;            <a class="code" href="classBPNet.html#aca57e8583a315a709a27e4dffeefd493">weights</a>[i] = <span class="keyword">new</span> <span class="keywordtype">double</span>[<a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>*<a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>];</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;            <a class="code" href="classBPNet.html#a72567d85f25041df70225b5e98ae3b90">gradAvgsWeights</a>[i] = <span class="keyword">new</span> <span class="keywordtype">double</span>[<a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>*<a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>];</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;            <a class="code" href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">biases</a>[i] = <span class="keyword">new</span> <span class="keywordtype">double</span>[n];</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;            <a class="code" href="classBPNet.html#a90e9fb8bde12a2520186d8084628109b">gradAvgsBiases</a>[i] = <span class="keyword">new</span> <span class="keywordtype">double</span>[n];</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;        }</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;    }        </div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;        </div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00069"></a><span class="lineno"><a class="line" href="classBPNet.html#acc0ad3e9fb7c706a4bc8676b3aaf47b8">   69</a></span>&#160;    <a class="code" href="classBPNet.html#acc0ad3e9fb7c706a4bc8676b3aaf47b8">BPNet</a>(<span class="keywordtype">int</span> nlayers,<span class="keyword">const</span> <span class="keywordtype">int</span> *layerCounts) : <a class="code" href="classNet.html">Net</a>(<a class="code" href="netType_8hpp.html#a1526df0fc932ccf720aa26267f923213">NetType</a>::<a class="code" href="netType_8hpp.html#a1526df0fc932ccf720aa26267f923213af62eb0bf5e5c72e80983fbbac1cb70e5">PLAIN</a>) {</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;        <a class="code" href="classBPNet.html#ada480f784f72fb5de132ce368adde531">init</a>(nlayers,layerCounts);</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    }</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    </div><div class="line"><a name="l00073"></a><span class="lineno"><a class="line" href="classBPNet.html#a98fa374aec169a3e741f2ce96fac7094">   73</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#a98fa374aec169a3e741f2ce96fac7094">setH</a>(<span class="keywordtype">double</span> h){</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;        <span class="comment">// does nothing, because this is an unmodulated net.</span></div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;    }</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;    </div><div class="line"><a name="l00077"></a><span class="lineno"><a class="line" href="classBPNet.html#aef1082e622022f25bee51013fab29aa0">   77</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">double</span> <a class="code" href="classBPNet.html#aef1082e622022f25bee51013fab29aa0">getH</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    }</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;    </div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    </div><div class="line"><a name="l00086"></a><span class="lineno"><a class="line" href="classBPNet.html#a7a452b3f05cc7e72b897a3546a38c010">   86</a></span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classBPNet.html#a7a452b3f05cc7e72b897a3546a38c010">~BPNet</a>(){</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;i++){</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;            <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#aca57e8583a315a709a27e4dffeefd493">weights</a>[i];</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;            <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">biases</a>[i];</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;            <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a72567d85f25041df70225b5e98ae3b90">gradAvgsWeights</a>[i];</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;            <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a90e9fb8bde12a2520186d8084628109b">gradAvgsBiases</a>[i];</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;            <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a>[i];</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;            <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a6b60b49ea0c157bbe4d785f74fa3f208">errors</a>[i];</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;        }</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;        <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#aca57e8583a315a709a27e4dffeefd493">weights</a>;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;        <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">biases</a>;</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;        <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a72567d85f25041df70225b5e98ae3b90">gradAvgsWeights</a>;</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;        <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a90e9fb8bde12a2520186d8084628109b">gradAvgsBiases</a>;</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;        <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a>;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a6b60b49ea0c157bbe4d785f74fa3f208">errors</a>;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        <span class="keyword">delete</span> [] <a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a>;</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;    }</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;    </div><div class="line"><a name="l00104"></a><span class="lineno"><a class="line" href="classBPNet.html#ad95c2a033ee8246637a6ce55e685429a">  104</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#ad95c2a033ee8246637a6ce55e685429a">setInputs</a>(<span class="keywordtype">double</span> *d) {</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;<a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a>[0];i++){</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;            <a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a>[0][i]=d[i];</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;        }</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    }</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    </div><div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classBPNet.html#ae9e80dbedb62e973efdef21745a4a27a">  115</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#ae9e80dbedb62e973efdef21745a4a27a">setInput</a>(<span class="keywordtype">int</span> n, <span class="keywordtype">double</span> d){</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;        <a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a>[0][n] = d;</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    }</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;        </div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    </div><div class="line"><a name="l00120"></a><span class="lineno"><a class="line" href="classBPNet.html#adf9256df2239cdef0cb7ad3b45d0e06e">  120</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">double</span> *<a class="code" href="classBPNet.html#adf9256df2239cdef0cb7ad3b45d0e06e">getOutputs</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a>[<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>-1];</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    }</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;    </div><div class="line"><a name="l00124"></a><span class="lineno"><a class="line" href="classBPNet.html#afbf10480c672d8a6e3cbf4071f447cc8">  124</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">int</span> <a class="code" href="classBPNet.html#afbf10480c672d8a6e3cbf4071f447cc8">getLayerSize</a>(<span class="keywordtype">int</span> n)<span class="keyword"> const </span>{</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a>[n];</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;    }</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;    </div><div class="line"><a name="l00128"></a><span class="lineno"><a class="line" href="classBPNet.html#af52311c47d488b0121ea59574e2b9c05">  128</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">int</span> <a class="code" href="classBPNet.html#af52311c47d488b0121ea59574e2b9c05">getLayerCount</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;    }</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;    </div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;        </div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;    </div><div class="line"><a name="l00134"></a><span class="lineno"><a class="line" href="classBPNet.html#ab0071a9b17ba5d42959ce600d29a255c">  134</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">int</span> <a class="code" href="classBPNet.html#ab0071a9b17ba5d42959ce600d29a255c">getDataSize</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;        <span class="comment">// number of weights+biases for each layer is</span></div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        <span class="comment">// the number of nodes in that layer (bias count)</span></div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;        <span class="comment">// times the number of nodes in the previous layer.</span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;        <span class="comment">// </span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;        <span class="comment">// NOTE THAT this uses the true layer size rather than</span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;        <span class="comment">// the fake version returned in the subclass HInputNet</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;        <span class="keywordtype">int</span> pc=0;</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;        <span class="keywordtype">int</span> total=0;</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;i++){</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;            <span class="keywordtype">int</span> c = <a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a>[i];</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;            total += c*(1+pc);</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;            pc = c;</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;        }</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        <span class="keywordflow">return</span> total;</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;    }</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;    </div><div class="line"><a name="l00151"></a><span class="lineno"><a class="line" href="classBPNet.html#a7ef14370548350daecedcb275ba88c07">  151</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#a7ef14370548350daecedcb275ba88c07">save</a>(<span class="keywordtype">double</span> *buf)<span class="keyword"> const </span>{</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;        <span class="keywordtype">double</span> *g=buf;</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;        <span class="comment">// data is ordered by layers, with nodes within</span></div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;        <span class="comment">// layers, and each node is bias then weights.</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;        <span class="comment">// </span></div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;        <span class="comment">// NOTE THAT this uses the true layer size rather than</span></div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        <span class="comment">// the fake version returned in the subclass HInputNet</span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;i++){</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;<a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a>[i];j++){</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;                *g++ = <a class="code" href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">biases</a>[i][j];</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;                <span class="keywordflow">if</span>(i){</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;                    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k=0;k&lt;layerSizes[i-1];k++){</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;                        *g++ = <a class="code" href="classBPNet.html#a20f1696c6c5449b79101dc4f345e599e">getw</a>(i,j,k);</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;                    }</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;                }</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;            }</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;        }</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;    }</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;    </div><div class="line"><a name="l00170"></a><span class="lineno"><a class="line" href="classBPNet.html#a11724f2263de9dcbc0f9172b464732c7">  170</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#a11724f2263de9dcbc0f9172b464732c7">load</a>(<span class="keywordtype">double</span> *buf){</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;        <span class="keywordtype">double</span> *g=buf;</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        <span class="comment">// genome is ordered by layers, with nodes within</span></div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;        <span class="comment">// layers, and each node is bias then weights.</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;        <span class="comment">// </span></div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;        <span class="comment">// NOTE THAT this uses the true layer size rather than</span></div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;        <span class="comment">// the fake version returned in the subclass HInputNet</span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;i++){</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;<a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a>[i];j++){</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;                <a class="code" href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">biases</a>[i][j]=*g++;</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;                <span class="keywordflow">if</span>(i){</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;                    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k=0;k&lt;layerSizes[i-1];k++){</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;                        <a class="code" href="classBPNet.html#a20f1696c6c5449b79101dc4f345e599e">getw</a>(i,j,k) = *g++;</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;                    }</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;                }</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;            }</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;        }</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;    }</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;    </div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00190"></a><span class="lineno"><a class="line" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">  190</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>; </div><div class="line"><a name="l00191"></a><span class="lineno"><a class="line" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">  191</a></span>&#160;    <span class="keywordtype">int</span> *<a class="code" href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">layerSizes</a>; </div><div class="line"><a name="l00192"></a><span class="lineno"><a class="line" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">  192</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>; </div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    </div><div class="line"><a name="l00205"></a><span class="lineno"><a class="line" href="classBPNet.html#aca57e8583a315a709a27e4dffeefd493">  205</a></span>&#160;    <span class="keywordtype">double</span> **<a class="code" href="classBPNet.html#aca57e8583a315a709a27e4dffeefd493">weights</a>;</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;    </div><div class="line"><a name="l00208"></a><span class="lineno"><a class="line" href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">  208</a></span>&#160;    <span class="keywordtype">double</span> **<a class="code" href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">biases</a>;</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;    </div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;    <span class="comment">// data generated during training and running</span></div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;    </div><div class="line"><a name="l00212"></a><span class="lineno"><a class="line" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">  212</a></span>&#160;    <span class="keywordtype">double</span> **<a class="code" href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">outputs</a>; </div><div class="line"><a name="l00213"></a><span class="lineno"><a class="line" href="classBPNet.html#a6b60b49ea0c157bbe4d785f74fa3f208">  213</a></span>&#160;    <span class="keywordtype">double</span> **<a class="code" href="classBPNet.html#a6b60b49ea0c157bbe4d785f74fa3f208">errors</a>; </div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;    </div><div class="line"><a name="l00215"></a><span class="lineno"><a class="line" href="classBPNet.html#a72567d85f25041df70225b5e98ae3b90">  215</a></span>&#160;    <span class="keywordtype">double</span> **<a class="code" href="classBPNet.html#a72567d85f25041df70225b5e98ae3b90">gradAvgsWeights</a>; </div><div class="line"><a name="l00216"></a><span class="lineno"><a class="line" href="classBPNet.html#a90e9fb8bde12a2520186d8084628109b">  216</a></span>&#160;    <span class="keywordtype">double</span> **<a class="code" href="classBPNet.html#a90e9fb8bde12a2520186d8084628109b">gradAvgsBiases</a>; </div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;    </div><div class="line"><a name="l00218"></a><span class="lineno"><a class="line" href="classBPNet.html#ae1b90b3c92f6be9af29005371da66543">  218</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#ae1b90b3c92f6be9af29005371da66543">initWeights</a>(<span class="keywordtype">double</span> initr){</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;i++){</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;            <span class="keywordtype">double</span> initrange;</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;            <span class="keywordflow">if</span>(i){</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;                <span class="keywordtype">double</span> ct = layerSizes[i-1];</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;                <span class="keywordflow">if</span>(initr&gt;0)</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;                    initrange = initr;</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;                    initrange = 1.0/sqrt(ct); <span class="comment">// from Bishop</span></div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;            } <span class="keywordflow">else</span> </div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;                initrange = 0.1; <span class="comment">// on input layer, should mean little.</span></div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;layerSizes[i];j++)</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;                biases[i][j]=<a class="code" href="classNet.html#aede931306b87045c0e6f14ee947a8ef7">drand</a>(-initrange,initrange);</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;largestLayerSize*<a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>;j++){</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;                weights[i][j]=<a class="code" href="classNet.html#aede931306b87045c0e6f14ee947a8ef7">drand</a>(-initrange,initrange);</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;            }</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;        }</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;        <span class="comment">// zero the input layer weights, which should be unused.</span></div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;layerSizes[0];j++)</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;            biases[0][j]=0;</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;largestLayerSize*<a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>;j++)</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;            weights[0][j]=0;</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;    }</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;    </div><div class="line"><a name="l00249"></a><span class="lineno"><a class="line" href="classBPNet.html#a20f1696c6c5449b79101dc4f345e599e">  249</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">double</span>&amp; <a class="code" href="classBPNet.html#a20f1696c6c5449b79101dc4f345e599e">getw</a>(<span class="keywordtype">int</span> tolayer,<span class="keywordtype">int</span> toneuron,<span class="keywordtype">int</span> fromneuron)<span class="keyword"> const </span>{</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;        <span class="keywordflow">return</span> weights[tolayer][toneuron+largestLayerSize*fromneuron];</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;    }</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;    </div><div class="line"><a name="l00259"></a><span class="lineno"><a class="line" href="classBPNet.html#a1ffbe006ab858291ec96c503696c3131">  259</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">double</span>&amp; <a class="code" href="classBPNet.html#a1ffbe006ab858291ec96c503696c3131">getb</a>(<span class="keywordtype">int</span> layer,<span class="keywordtype">int</span> neuron)<span class="keyword"> const </span>{</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;        <span class="keywordflow">return</span> biases[layer][neuron];</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;    }</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;    </div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;    </div><div class="line"><a name="l00272"></a><span class="lineno"><a class="line" href="classBPNet.html#a48d88671bda131e1a6d0baab080b6df6">  272</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">double</span>&amp; <a class="code" href="classBPNet.html#a48d88671bda131e1a6d0baab080b6df6">getavggradw</a>(<span class="keywordtype">int</span> tolayer,<span class="keywordtype">int</span> toneuron,<span class="keywordtype">int</span> fromneuron)<span class="keyword"> const </span>{</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;        <span class="keywordflow">return</span> gradAvgsWeights[tolayer][toneuron+largestLayerSize*fromneuron];</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;    }</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;    </div><div class="line"><a name="l00283"></a><span class="lineno"><a class="line" href="classBPNet.html#a916264dd0b58dcfae3d473231f7d0892">  283</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">double</span> <a class="code" href="classBPNet.html#a916264dd0b58dcfae3d473231f7d0892">getavggradb</a>(<span class="keywordtype">int</span> l,<span class="keywordtype">int</span> n)<span class="keyword"> const </span>{</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;        <span class="keywordflow">return</span> gradAvgsBiases[l][n];</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;    }</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;    </div><div class="line"><a name="l00294"></a><span class="lineno"><a class="line" href="classBPNet.html#a98e5db7247f0358375c27d1bb091f6ab">  294</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#a98e5db7247f0358375c27d1bb091f6ab">calcError</a>(<span class="keywordtype">double</span> *in,<span class="keywordtype">double</span> *out){</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;        <span class="comment">// first run the network forwards</span></div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;        <a class="code" href="classBPNet.html#ad95c2a033ee8246637a6ce55e685429a">setInputs</a>(in);</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;        <a class="code" href="classBPNet.html#af60f5bfa6cb7dffd75a9a127b811a208">update</a>();</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;        </div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;        <span class="comment">// first, calculate the error in the output layer</span></div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;        <span class="keywordtype">int</span> ol = numLayers-1;</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;layerSizes[ol];i++){</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;            <span class="keywordtype">double</span> o = outputs[ol][i];</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;            errors[ol][i] = o*(1-o)*(o-out[i]);</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;        }</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;        </div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;        <span class="comment">// then work out the errors in all the other layers</span></div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> l=1;l&lt;numLayers-1;l++){</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;layerSizes[l];j++){</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;                <span class="keywordtype">double</span> e = 0;</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;                <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;layerSizes[l+1];i++)</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;                    e += errors[l+1][i]*<a class="code" href="classBPNet.html#a20f1696c6c5449b79101dc4f345e599e">getw</a>(l+1,i,j);</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;                </div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;                <span class="comment">// produce the \delta^l_i term where l is the layer and i</span></div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;                <span class="comment">// the index of the node</span></div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;                errors[l][j] = e * outputs[l][j] * (1-outputs[l][j]); </div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;            }</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;        }</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;    }</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;    </div><div class="line"><a name="l00320"></a><span class="lineno"><a class="line" href="classBPNet.html#af60f5bfa6cb7dffd75a9a127b811a208">  320</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classBPNet.html#af60f5bfa6cb7dffd75a9a127b811a208">update</a>(){</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=1;i&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;i++){</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;layerSizes[i];j++){</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;                <span class="keywordtype">double</span> v = biases[i][j];</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;                <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k=0;k&lt;layerSizes[i-1];k++){</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;                    v += <a class="code" href="classBPNet.html#a20f1696c6c5449b79101dc4f345e599e">getw</a>(i,j,k) * outputs[i-1][k];</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;                }</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;                outputs[i][j]=<a class="code" href="net_8hpp.html#aa924e8c95bc498ebc9f8e08a0c491e7c">sigmoid</a>(v);</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;            }</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;        }</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;    }</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;    </div><div class="line"><a name="l00332"></a><span class="lineno"><a class="line" href="classBPNet.html#a3f820464f3338ed7305e9de950cd2103">  332</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">double</span> <a class="code" href="classBPNet.html#a3f820464f3338ed7305e9de950cd2103">trainBatch</a>(<a class="code" href="classExampleSet.html">ExampleSet</a>&amp; ex,<span class="keywordtype">int</span> start,<span class="keywordtype">int</span> num,<span class="keywordtype">double</span> eta){</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;        <span class="comment">// zero average gradients</span></div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;j++){</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k=0;k&lt;layerSizes[j];k++)</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;                gradAvgsBiases[j][k]=0;</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;largestLayerSize*<a class="code" href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">largestLayerSize</a>;i++)</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;                gradAvgsWeights[j][i]=0;</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;        }</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;        </div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;        <span class="comment">// reset total error</span></div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;        <span class="keywordtype">double</span> totalError=0;</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;        <span class="comment">// iterate over examples</span></div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> nn=0;nn&lt;num;nn++){</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;            <span class="keywordtype">int</span> exampleIndex = nn+start;</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;            <span class="comment">// set modulator</span></div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;            <a class="code" href="classBPNet.html#a98fa374aec169a3e741f2ce96fac7094">setH</a>(ex.<a class="code" href="classExampleSet.html#a084224adb0fdf5555caa24a0bd4d4211">getH</a>(exampleIndex));</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;            <span class="comment">// get outputs for this example</span></div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;            <span class="keywordtype">double</span> *outs = ex.<a class="code" href="classExampleSet.html#a97c5c5596d388c2adcb1f761472d18aa">getOutputs</a>(exampleIndex);</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;            <span class="comment">// build errors for each example</span></div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;            <a class="code" href="classBPNet.html#a98e5db7247f0358375c27d1bb091f6ab">calcError</a>(ex.<a class="code" href="classExampleSet.html#a77229f0f933a885f5bffc6e46cafe432">getInputs</a>(exampleIndex),outs);</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;            </div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;            <span class="comment">// accumulate errors</span></div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> l=1;l&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;l++){</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;                <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;layerSizes[l];i++){</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;                    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;layerSizes[l-1];j++)</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;                        <a class="code" href="classBPNet.html#a48d88671bda131e1a6d0baab080b6df6">getavggradw</a>(l,i,j) += errors[l][i]*outputs[l-1][j];</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;                    gradAvgsBiases[l][i] += errors[l][i];</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;                }</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;            }</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;            <span class="comment">// count up the total error</span></div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;            <span class="keywordtype">int</span> ol = numLayers-1;</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;layerSizes[ol];i++){</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;                <span class="keywordtype">double</span> o = outputs[ol][i];</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;                <span class="keywordtype">double</span> e = (o-outs[i]);</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;                totalError += e*e;</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;            }</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;        }</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;        </div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;        <span class="comment">// for calculating average error - 1/number of examples trained</span></div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;        <span class="keywordtype">double</span> factor = 1.0/(double)num;</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;        <span class="comment">// we now have a full set of running averages. Time to apply them.</span></div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">int</span> l=1;l&lt;<a class="code" href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">numLayers</a>;l++){</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0;i&lt;layerSizes[l];i++){</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;                <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j=0;j&lt;layerSizes[l-1];j++){</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;                    <span class="keywordtype">double</span> wdelta = eta*<a class="code" href="classBPNet.html#a48d88671bda131e1a6d0baab080b6df6">getavggradw</a>(l,i,j)*factor;</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;<span class="comment">//                    printf(&quot;WCORR: %f factor %f\n&quot;,wdelta,getavggradw(l,i,j));</span></div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;                    <a class="code" href="classBPNet.html#a20f1696c6c5449b79101dc4f345e599e">getw</a>(l,i,j) -= wdelta;</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;                }</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;                <span class="keywordtype">double</span> bdelta = eta*gradAvgsBiases[l][i]*factor;</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;                biases[l][i] -= bdelta;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;            }</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;        }</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;        <span class="comment">// and return total error - this is the SUM of the MSE of each output</span></div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;        <span class="keywordflow">return</span> totalError*factor;</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;    }</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;};</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;<span class="preprocessor">#endif </span><span class="comment">/* __BPNET_HPP */</span><span class="preprocessor"></span></div><div class="ttc" id="classBPNet_html_acc0ad3e9fb7c706a4bc8676b3aaf47b8"><div class="ttname"><a href="classBPNet.html#acc0ad3e9fb7c706a4bc8676b3aaf47b8">BPNet::BPNet</a></div><div class="ttdeci">BPNet(int nlayers, const int *layerCounts)</div><div class="ttdoc">Constructor - does not initialise the weights to random values so that we can reinitialise networks...</div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00069">bpnet.hpp:69</a></div></div>
<div class="ttc" id="netType_8hpp_html_a1526df0fc932ccf720aa26267f923213"><div class="ttname"><a href="netType_8hpp.html#a1526df0fc932ccf720aa26267f923213">NetType</a></div><div class="ttdeci">NetType</div><div class="ttdoc">The different types of network - each has an associated integer for saving/loading file data...</div><div class="ttdef"><b>Definition:</b> <a href="netType_8hpp_source.html#l00015">netType.hpp:15</a></div></div>
<div class="ttc" id="classBPNet_html_ad95c2a033ee8246637a6ce55e685429a"><div class="ttname"><a href="classBPNet.html#ad95c2a033ee8246637a6ce55e685429a">BPNet::setInputs</a></div><div class="ttdeci">virtual void setInputs(double *d)</div><div class="ttdoc">Set the inputs to the network before running or training. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00104">bpnet.hpp:104</a></div></div>
<div class="ttc" id="classBPNet_html_a90e9fb8bde12a2520186d8084628109b"><div class="ttname"><a href="classBPNet.html#a90e9fb8bde12a2520186d8084628109b">BPNet::gradAvgsBiases</a></div><div class="ttdeci">double ** gradAvgsBiases</div><div class="ttdoc">average gradient for each bias (built during training) </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00216">bpnet.hpp:216</a></div></div>
<div class="ttc" id="classBPNet_html_ad9b8ec22ef6319ebda7b3ac996b76f3e"><div class="ttname"><a href="classBPNet.html#ad9b8ec22ef6319ebda7b3ac996b76f3e">BPNet::BPNet</a></div><div class="ttdeci">BPNet()</div><div class="ttdoc">Special constructor for subclasses which need to manipulate layer count before initialisation (e...</div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00024">bpnet.hpp:24</a></div></div>
<div class="ttc" id="classBPNet_html_ada480f784f72fb5de132ce368adde531"><div class="ttname"><a href="classBPNet.html#ada480f784f72fb5de132ce368adde531">BPNet::init</a></div><div class="ttdeci">void init(int nlayers, const int *layerCounts)</div><div class="ttdoc">Initialiser for use by the main constructor and the ctors of those subclasses mentioned in BPNet() ...</div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00032">bpnet.hpp:32</a></div></div>
<div class="ttc" id="classBPNet_html_a98e5db7247f0358375c27d1bb091f6ab"><div class="ttname"><a href="classBPNet.html#a98e5db7247f0358375c27d1bb091f6ab">BPNet::calcError</a></div><div class="ttdeci">void calcError(double *in, double *out)</div><div class="ttdoc">run a single example and calculate the errors; used in training. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00294">bpnet.hpp:294</a></div></div>
<div class="ttc" id="classBPNet_html_aaabccfce85225083b21b02a3b3065c81"><div class="ttname"><a href="classBPNet.html#aaabccfce85225083b21b02a3b3065c81">BPNet::numLayers</a></div><div class="ttdeci">int numLayers</div><div class="ttdoc">number of layers, including input and output </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00190">bpnet.hpp:190</a></div></div>
<div class="ttc" id="classBPNet_html_a2e41caf79f495792d03395b0c3eea560"><div class="ttname"><a href="classBPNet.html#a2e41caf79f495792d03395b0c3eea560">BPNet::biases</a></div><div class="ttdeci">double ** biases</div><div class="ttdoc">array of biases, stored as a rectangular array of [layer][node] </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00208">bpnet.hpp:208</a></div></div>
<div class="ttc" id="net_8hpp_html"><div class="ttname"><a href="net_8hpp.html">net.hpp</a></div><div class="ttdoc">This is the abstract basic network class - the training methods are in each subclass. </div></div>
<div class="ttc" id="classBPNet_html_a48d88671bda131e1a6d0baab080b6df6"><div class="ttname"><a href="classBPNet.html#a48d88671bda131e1a6d0baab080b6df6">BPNet::getavggradw</a></div><div class="ttdeci">double &amp; getavggradw(int tolayer, int toneuron, int fromneuron) const </div><div class="ttdoc">get the value of the gradient for a given weight </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00272">bpnet.hpp:272</a></div></div>
<div class="ttc" id="classBPNet_html_a11724f2263de9dcbc0f9172b464732c7"><div class="ttname"><a href="classBPNet.html#a11724f2263de9dcbc0f9172b464732c7">BPNet::load</a></div><div class="ttdeci">virtual void load(double *buf)</div><div class="ttdoc">Given that the pointer points to a data block of the correct size for the current network...</div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00170">bpnet.hpp:170</a></div></div>
<div class="ttc" id="netType_8hpp_html_a1526df0fc932ccf720aa26267f923213af62eb0bf5e5c72e80983fbbac1cb70e5"><div class="ttname"><a href="netType_8hpp.html#a1526df0fc932ccf720aa26267f923213af62eb0bf5e5c72e80983fbbac1cb70e5">NetType::PLAIN</a></div></div>
<div class="ttc" id="classBPNet_html"><div class="ttname"><a href="classBPNet.html">BPNet</a></div><div class="ttdoc">The &quot;basic&quot; back-propagation network using a logistic sigmoid, as described by Rumelhart, Hinton and Williams (and many others). This class is used by output blending and h-as-input networks. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00018">bpnet.hpp:18</a></div></div>
<div class="ttc" id="classExampleSet_html_a97c5c5596d388c2adcb1f761472d18aa"><div class="ttname"><a href="classExampleSet.html#a97c5c5596d388c2adcb1f761472d18aa">ExampleSet::getOutputs</a></div><div class="ttdeci">double * getOutputs(int example)</div><div class="ttdoc">Get a pointer to the outputs for a given example, for reading or writing. </div><div class="ttdef"><b>Definition:</b> <a href="data_8hpp_source.html#l00349">data.hpp:349</a></div></div>
<div class="ttc" id="net_8hpp_html_aa924e8c95bc498ebc9f8e08a0c491e7c"><div class="ttname"><a href="net_8hpp.html#aa924e8c95bc498ebc9f8e08a0c491e7c">sigmoid</a></div><div class="ttdeci">double sigmoid(double x)</div><div class="ttdef"><b>Definition:</b> <a href="net_8hpp_source.html#l00020">net.hpp:20</a></div></div>
<div class="ttc" id="classBPNet_html_af60f5bfa6cb7dffd75a9a127b811a208"><div class="ttname"><a href="classBPNet.html#af60f5bfa6cb7dffd75a9a127b811a208">BPNet::update</a></div><div class="ttdeci">virtual void update()</div><div class="ttdoc">Run a single update of the network. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00320">bpnet.hpp:320</a></div></div>
<div class="ttc" id="classBPNet_html_a3f820464f3338ed7305e9de950cd2103"><div class="ttname"><a href="classBPNet.html#a3f820464f3338ed7305e9de950cd2103">BPNet::trainBatch</a></div><div class="ttdeci">virtual double trainBatch(ExampleSet &amp;ex, int start, int num, double eta)</div><div class="ttdoc">Train a network for batch (or mini-batch) (or single example). </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00332">bpnet.hpp:332</a></div></div>
<div class="ttc" id="classBPNet_html_a7ef14370548350daecedcb275ba88c07"><div class="ttname"><a href="classBPNet.html#a7ef14370548350daecedcb275ba88c07">BPNet::save</a></div><div class="ttdeci">virtual void save(double *buf) const </div><div class="ttdoc">Serialize the data (not including any network type magic number or layer/node counts) to the given me...</div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00151">bpnet.hpp:151</a></div></div>
<div class="ttc" id="classBPNet_html_a20f1696c6c5449b79101dc4f345e599e"><div class="ttname"><a href="classBPNet.html#a20f1696c6c5449b79101dc4f345e599e">BPNet::getw</a></div><div class="ttdeci">double &amp; getw(int tolayer, int toneuron, int fromneuron) const </div><div class="ttdoc">get the value of a weight. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00249">bpnet.hpp:249</a></div></div>
<div class="ttc" id="classBPNet_html_ab0071a9b17ba5d42959ce600d29a255c"><div class="ttname"><a href="classBPNet.html#ab0071a9b17ba5d42959ce600d29a255c">BPNet::getDataSize</a></div><div class="ttdeci">virtual int getDataSize() const </div><div class="ttdoc">Get the length of the serialised data block for this network. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00134">bpnet.hpp:134</a></div></div>
<div class="ttc" id="classBPNet_html_a1ffbe006ab858291ec96c503696c3131"><div class="ttname"><a href="classBPNet.html#a1ffbe006ab858291ec96c503696c3131">BPNet::getb</a></div><div class="ttdeci">double &amp; getb(int layer, int neuron) const </div><div class="ttdoc">get the value of a bias </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00259">bpnet.hpp:259</a></div></div>
<div class="ttc" id="classBPNet_html_ae1b90b3c92f6be9af29005371da66543"><div class="ttname"><a href="classBPNet.html#ae1b90b3c92f6be9af29005371da66543">BPNet::initWeights</a></div><div class="ttdeci">virtual void initWeights(double initr)</div><div class="ttdoc">initialise weights to random values </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00218">bpnet.hpp:218</a></div></div>
<div class="ttc" id="classBPNet_html_a916264dd0b58dcfae3d473231f7d0892"><div class="ttname"><a href="classBPNet.html#a916264dd0b58dcfae3d473231f7d0892">BPNet::getavggradb</a></div><div class="ttdeci">double getavggradb(int l, int n) const </div><div class="ttdoc">get the value of a bias gradient </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00283">bpnet.hpp:283</a></div></div>
<div class="ttc" id="classBPNet_html_a98fa374aec169a3e741f2ce96fac7094"><div class="ttname"><a href="classBPNet.html#a98fa374aec169a3e741f2ce96fac7094">BPNet::setH</a></div><div class="ttdeci">virtual void setH(double h)</div><div class="ttdoc">Set the modulator level for subsequent runs and training of this network. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00073">bpnet.hpp:73</a></div></div>
<div class="ttc" id="classBPNet_html_af2839f081e9f715b207fcc89789bfd0a"><div class="ttname"><a href="classBPNet.html#af2839f081e9f715b207fcc89789bfd0a">BPNet::outputs</a></div><div class="ttdeci">double ** outputs</div><div class="ttdoc">outputs of each layer: one array of doubles for each </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00212">bpnet.hpp:212</a></div></div>
<div class="ttc" id="classBPNet_html_a6b60b49ea0c157bbe4d785f74fa3f208"><div class="ttname"><a href="classBPNet.html#a6b60b49ea0c157bbe4d785f74fa3f208">BPNet::errors</a></div><div class="ttdeci">double ** errors</div><div class="ttdoc">the error for each node, calculated by calcError() </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00213">bpnet.hpp:213</a></div></div>
<div class="ttc" id="classBPNet_html_af52311c47d488b0121ea59574e2b9c05"><div class="ttname"><a href="classBPNet.html#af52311c47d488b0121ea59574e2b9c05">BPNet::getLayerCount</a></div><div class="ttdeci">virtual int getLayerCount() const </div><div class="ttdoc">Get the number of layers. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00128">bpnet.hpp:128</a></div></div>
<div class="ttc" id="classBPNet_html_afbf10480c672d8a6e3cbf4071f447cc8"><div class="ttname"><a href="classBPNet.html#afbf10480c672d8a6e3cbf4071f447cc8">BPNet::getLayerSize</a></div><div class="ttdeci">virtual int getLayerSize(int n) const </div><div class="ttdoc">Get the number of nodes in a given layer. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00124">bpnet.hpp:124</a></div></div>
<div class="ttc" id="classBPNet_html_adf9256df2239cdef0cb7ad3b45d0e06e"><div class="ttname"><a href="classBPNet.html#adf9256df2239cdef0cb7ad3b45d0e06e">BPNet::getOutputs</a></div><div class="ttdeci">virtual double * getOutputs() const </div><div class="ttdoc">Get the outputs after running. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00120">bpnet.hpp:120</a></div></div>
<div class="ttc" id="classBPNet_html_a7a452b3f05cc7e72b897a3546a38c010"><div class="ttname"><a href="classBPNet.html#a7a452b3f05cc7e72b897a3546a38c010">BPNet::~BPNet</a></div><div class="ttdeci">virtual ~BPNet()</div><div class="ttdoc">destructor </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00086">bpnet.hpp:86</a></div></div>
<div class="ttc" id="classBPNet_html_ae9e80dbedb62e973efdef21745a4a27a"><div class="ttname"><a href="classBPNet.html#ae9e80dbedb62e973efdef21745a4a27a">BPNet::setInput</a></div><div class="ttdeci">void setInput(int n, double d)</div><div class="ttdoc">Used to set inputs manually, typically in HInputNet. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00115">bpnet.hpp:115</a></div></div>
<div class="ttc" id="classExampleSet_html_a084224adb0fdf5555caa24a0bd4d4211"><div class="ttname"><a href="classExampleSet.html#a084224adb0fdf5555caa24a0bd4d4211">ExampleSet::getH</a></div><div class="ttdeci">double getH(int example) const </div><div class="ttdoc">Get the h (modulator) for a given example. </div><div class="ttdef"><b>Definition:</b> <a href="data_8hpp_source.html#l00359">data.hpp:359</a></div></div>
<div class="ttc" id="classBPNet_html_a72567d85f25041df70225b5e98ae3b90"><div class="ttname"><a href="classBPNet.html#a72567d85f25041df70225b5e98ae3b90">BPNet::gradAvgsWeights</a></div><div class="ttdeci">double ** gradAvgsWeights</div><div class="ttdoc">average gradient for each weight (built during training) </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00215">bpnet.hpp:215</a></div></div>
<div class="ttc" id="classBPNet_html_aef1082e622022f25bee51013fab29aa0"><div class="ttname"><a href="classBPNet.html#aef1082e622022f25bee51013fab29aa0">BPNet::getH</a></div><div class="ttdeci">virtual double getH() const </div><div class="ttdoc">get the modulator level </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00077">bpnet.hpp:77</a></div></div>
<div class="ttc" id="classBPNet_html_aca57e8583a315a709a27e4dffeefd493"><div class="ttname"><a href="classBPNet.html#aca57e8583a315a709a27e4dffeefd493">BPNet::weights</a></div><div class="ttdeci">double ** weights</div><div class="ttdoc">Array of weights as [tolayer][tonode+largestLayerSize*fromnode]. </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00205">bpnet.hpp:205</a></div></div>
<div class="ttc" id="classNet_html"><div class="ttname"><a href="classNet.html">Net</a></div><div class="ttdoc">The abstract network type upon which all others are based. It&amp;#39;s not pure virtual, in that it encapsul...</div><div class="ttdef"><b>Definition:</b> <a href="net_8hpp_source.html#l00039">net.hpp:39</a></div></div>
<div class="ttc" id="classBPNet_html_a60c06f158b82c2ee8a95df4f0c46235d"><div class="ttname"><a href="classBPNet.html#a60c06f158b82c2ee8a95df4f0c46235d">BPNet::largestLayerSize</a></div><div class="ttdeci">int largestLayerSize</div><div class="ttdoc">number of nodes in largest layer </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00192">bpnet.hpp:192</a></div></div>
<div class="ttc" id="classExampleSet_html_a77229f0f933a885f5bffc6e46cafe432"><div class="ttname"><a href="classExampleSet.html#a77229f0f933a885f5bffc6e46cafe432">ExampleSet::getInputs</a></div><div class="ttdeci">double * getInputs(int example)</div><div class="ttdoc">Get a pointer to the inputs for a given example, for reading or writing. </div><div class="ttdef"><b>Definition:</b> <a href="data_8hpp_source.html#l00338">data.hpp:338</a></div></div>
<div class="ttc" id="classNet_html_aede931306b87045c0e6f14ee947a8ef7"><div class="ttname"><a href="classNet.html#aede931306b87045c0e6f14ee947a8ef7">Net::drand</a></div><div class="ttdeci">double drand(double mn, double mx)</div><div class="ttdoc">get a random number using this net&amp;#39;s PRNG data </div><div class="ttdef"><b>Definition:</b> <a href="net_8hpp_source.html#l00591">net.hpp:591</a></div></div>
<div class="ttc" id="classExampleSet_html"><div class="ttname"><a href="classExampleSet.html">ExampleSet</a></div><div class="ttdoc">A set of example data. Each datum consists of hormone (i.e. modulator value), inputs and outputs...</div><div class="ttdef"><b>Definition:</b> <a href="data_8hpp_source.html#l00057">data.hpp:57</a></div></div>
<div class="ttc" id="classBPNet_html_a9f59cc3cc5e0972d473e26a4fb47b5c6"><div class="ttname"><a href="classBPNet.html#a9f59cc3cc5e0972d473e26a4fb47b5c6">BPNet::layerSizes</a></div><div class="ttdeci">int * layerSizes</div><div class="ttdoc">array of layer sizes </div><div class="ttdef"><b>Definition:</b> <a href="bpnet_8hpp_source.html#l00191">bpnet.hpp:191</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
